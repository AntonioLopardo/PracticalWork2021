{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(os.path.join(cur_dir, 'data'))\n",
    "!git clone https://gitlab.cs.washington.edu/ALGES/TACL2015.git\n",
    "!git clone https://github.com/chaochun/nlu-asdiv-dataset.git\n",
    "!git clone https://github.com/openai/grade-school-math.git\n",
    "os.chdir(cur_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load asdiv\"\"\"\n",
    "\n",
    "if model_name == \"gpt-j\":\n",
    "    priming_text_path = \"data/priming_texts/asdiv/asdiv_prefix.txt\" # for gpt-j\n",
    "else:\n",
    "    priming_text_path = \"data/priming_texts/asdiv/asdiv_prefix_codegen.txt\" # for codegen\n",
    "\n",
    "current_dataset = dh.init_dataset_from_name(\"asdiv\", primingtext_path = priming_text_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CodeGen_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from termcolor import colored\n",
    "import wandb\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dataset_handler as dh\n",
    "import loading_utils as lu\n",
    "import testing_utils as tu\n",
    "\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\"\n",
    "\n",
    "#model_name = \"gpt-j\"\n",
    "model_name = \"codegen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'exp_impl.func_def_eq_short' from '/home/PracticalWork2021/exp_impl/func_def_eq_short.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import exp_impl.func_def_eq_short as exp_impl\n",
    "\n",
    "#priming_text_path = \"data/priming_texts/gsm8k/clustering_prompt/4_clusters/cluster_3.txt\"  # for codegen\n",
    "#priming_text_path = \"data/priming_texts/gsm8k/codegen/func_eq_short.txt\"\n",
    "priming_text_path = \"data/priming_texts/gsm8k/concepts_prompt/part-whole_3.txt\"\n",
    "#wandb_run_name = \"@100-codegen-0\"\n",
    "importlib.reload(exp_impl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading parameters\n",
      "loading parameters took 435.85s\n",
      "loading tokenizer\n",
      "loading tokenizer took 4.15s\n"
     ]
    }
   ],
   "source": [
    "if model_name == \"gpt-j\":\n",
    "    \"\"\"GPT-J and codeparrot models run in HFTest venv\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(gptj_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(gptj_model).half().eval().cuda()\n",
    "elif model_name == \"codegen\":\n",
    "    \"\"\"CodeGen runs in the venv venv\"\"\"\n",
    "    model_args = lu.model_args()\n",
    "    #model_args.model = \"codegen-350M-mono\"\n",
    "    model, tokenizer = lu.load_CodeGen(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load gsm8k\"\"\"\n",
    "\n",
    "if model_name == \"gpt-j\":\n",
    "    priming_text_path = (\n",
    "        \"data/priming_texts/gsm8k/gpt-j/gsm8k_fewer_alt.txt\"  # for gpt-j\n",
    "    )\n",
    "    current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\", primingtext_path=priming_text_path\n",
    "    )\n",
    "else:\n",
    "    current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\",\n",
    "        primingtext_path=priming_text_path,\n",
    "        sample_func=exp_impl.sample_n_for_prompting,\n",
    "        generate_prompt_func=exp_impl.generate_prompt,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4547 1364 2033 2409 2181 5082 2184 6995 5480 3775 2096 5997 5205 4924\n",
      " 4211  458 4763  620 4365 6025 1085 6287 5469 3426 3602  270 7270 4445\n",
      " 6584  777 4659 7108 5045 3893 5959 2875 6314 4506 6466 1894 3081 1765\n",
      " 3453 2542 7249 3947 3855 1500 4443  491  575  598 7199 3092 2733 2581\n",
      " 6856 7132 2076  735 2607 1418 2989 5122 4518 4295 6111 3195 1400 1241\n",
      " 5060 3365 5483 4546 1574 5430 4054 4519 6778 5166 3718 2399 3232 4937\n",
      " 7138 2055 5502 1417 2018 4838 6570 6163 4923 4400 1929 6672 6256  206\n",
      "  118 4857]\n",
      "\u001b[34mdef exercise4():\n",
      "    \"\"\"Vivian plays 10 Spotify songs every day. Her best friend Clara plays 2 fewer songs each day. If in June they didn't play any song during the weekends only, and there were 8 weekend days in June, what's the total number of songs they both listened to in that month? Hint: use these equations eq1: 30-8=22 eq2: 10*22=220 eq3: 10-2=8 eq4: 8*22=176 eq5: 220+176=396\"\"\"\u001b[0m\n",
      "\u001b[32m396\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tu.set_all_seeds()\n",
    "#tu.set_all_seeds_alt()\n",
    "\n",
    "sample_q_list, sample_a_list = current_dataset.sample_n_for_prompting(100)\n",
    "\n",
    "with open(\"test_prompt.txt\", \"w\") as f:\n",
    "    f.write(current_dataset.generate_prompt(sample_q_list[0]))\n",
    "\n",
    "print(colored(sample_q_list[3], \"blue\"))\n",
    "print(colored(sample_a_list[3], \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTESTING STARTED\u001b[0m\n",
      "\u001b[37m@sample 5 -> Pass@3 = 0.52\u001b[0m\n",
      "\u001b[37m@sample 10 -> Pass@3 = 0.36\u001b[0m\n",
      "\u001b[37m@sample 15 -> Pass@3 = 0.4000000000000001\u001b[0m\n",
      "\u001b[37m@sample 20 -> Pass@3 = 0.35\u001b[0m\n",
      "\u001b[37m@sample 25 -> Pass@3 = 0.4\u001b[0m\n",
      "\u001b[37m@sample 30 -> Pass@3 = 0.38333333333333336\u001b[0m\n",
      "\u001b[37m@sample 35 -> Pass@3 = 0.4\u001b[0m\n",
      "\u001b[37m@sample 40 -> Pass@3 = 0.365\u001b[0m\n",
      "\u001b[37m@sample 45 -> Pass@3 = 0.36666666666666664\u001b[0m\n",
      "\u001b[37m@sample 50 -> Pass@3 = 0.38\u001b[0m\n",
      "\u001b[37m@sample 55 -> Pass@3 = 0.4036363636363637\u001b[0m\n",
      "\u001b[37m@sample 60 -> Pass@3 = 0.4066666666666667\u001b[0m\n",
      "\u001b[37m@sample 65 -> Pass@3 = 0.38923076923076927\u001b[0m\n",
      "\u001b[37m@sample 70 -> Pass@3 = 0.3985714285714286\u001b[0m\n",
      "\u001b[37m@sample 75 -> Pass@3 = 0.42266666666666663\u001b[0m\n",
      "\u001b[37m@sample 80 -> Pass@3 = 0.40875000000000006\u001b[0m\n",
      "\u001b[37m@sample 85 -> Pass@3 = 0.39647058823529413\u001b[0m\n",
      "\u001b[37m@sample 90 -> Pass@3 = 0.4133333333333334\u001b[0m\n",
      "\u001b[37m@sample 95 -> Pass@3 = 0.4273684210526316\u001b[0m\n",
      "\u001b[37m@sample 100 -> Pass@3 = 0.41800000000000004\u001b[0m\n",
      "\u001b[32m\n",
      "\n",
      "Pass@3 = 0.41800000000000004\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Set up for CodeGen\n",
    "config = lu.codegen_gen_args()\n",
    "#config.num_return_sequences = 4 # 4 for gsm8k 5 for asdiv\n",
    "config.num_return_sequences = 5\n",
    "config.k = 3\n",
    "config.max_lenght_after_input = 250\n",
    "#config.top_p = 0.95\n",
    "config.top_p = 0.95\n",
    "config.top_k = 50\n",
    "#config.temperature = 0.7\n",
    "config.temperature = 0.61\n",
    "config.min_length = 3\n",
    "\n",
    "tu.set_all_seeds(model_name)\n",
    "_, part_whole_pass_at_k = tu.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config, func_def_mod=True, print_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTransfer prompts - Pass@3 = 0.409\u001b[0m\n",
      "\u001b[32mTransfer prompts - Pass@3 = 0.316\u001b[0m\n",
      "\u001b[32mTransfer prompts - Pass@3 = 0.3600000000000001\u001b[0m\n",
      "\u001b[32mTransfer prompts - Pass@3 = 0.376\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(colored(f\"Transfer prompts - Pass@{3} = {np.mean(np.array(cluster_0_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"Transfer prompts - Pass@{3} = {np.mean(np.array(cluster_1_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"Transfer prompts - Pass@{3} = {np.mean(np.array(cluster_2_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"Transfer prompts - Pass@{3} = {np.mean(np.array(cluster_3_pass_at_k))}\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"clustering_exp/cluster_0_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_0_pass_at_k, f)\n",
    "with open(\"clustering_exp/cluster_1_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_1_pass_at_k, f)\n",
    "with open(\"clustering_exp/cluster_2_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_2_pass_at_k, f)\n",
    "with open(\"clustering_exp/cluster_3_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(cluster_3_pass_at_k, f)\n",
    "with open(\"clustering_exp/general_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(general_pass_at_k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'part_whole_pass_at_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/PracticalWork2021/BenchmarkingNotebook.ipynb Cell 13'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B65.108.33.99/home/PracticalWork2021/BenchmarkingNotebook.ipynb#ch0000017vscode-remote?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(colored(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPart-whole promts - Pass@\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m3\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m = \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(part_whole_pass_at_k))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'part_whole_pass_at_k' is not defined"
     ]
    }
   ],
   "source": [
    "print(colored(f\"Part-whole promts - Pass@{3} = {np.mean(np.array(part_whole_pass_at_k))}\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mTransfer prompts - Pass@3 = 0.345\u001b[0m\n",
      "\u001b[32mDimansional analysis promts - Pass@3 = 0.318\u001b[0m\n",
      "\u001b[32mExplicit math promts - Pass@3 = 0.37799999999999995\u001b[0m\n",
      "\u001b[32mPart-whole promts - Pass@3 = 0.41800000000000004\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'general_pass_at_k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/PracticalWork2021/BenchmarkingNotebook.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B65.108.33.99/home/PracticalWork2021/BenchmarkingNotebook.ipynb#ch0000010vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(colored(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExplicit math promts - Pass@\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m3\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m = \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(explicit_math_pass_at_k))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B65.108.33.99/home/PracticalWork2021/BenchmarkingNotebook.ipynb#ch0000010vscode-remote?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(colored(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPart-whole promts - Pass@\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m3\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m = \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(part_whole_pass_at_k))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B65.108.33.99/home/PracticalWork2021/BenchmarkingNotebook.ipynb#ch0000010vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(colored(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGeneral prompts - Pass@\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m3\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m = \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mmean(np\u001b[39m.\u001b[39marray(general_pass_at_k))\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mgreen\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'general_pass_at_k' is not defined"
     ]
    }
   ],
   "source": [
    "print(colored(f\"Transfer prompts - Pass@{3} = {np.mean(np.array(transfer_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"Dimansional analysis promts - Pass@{3} = {np.mean(np.array(dimension_analysis_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"Explicit math promts - Pass@{3} = {np.mean(np.array(explicit_math_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"Part-whole promts - Pass@{3} = {np.mean(np.array(part_whole_pass_at_k))}\", \"green\"))\n",
    "print(colored(f\"General prompts - Pass@{3} = {np.mean(np.array(general_pass_at_k))}\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"transfer_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(transfer_pass_at_k, f)\n",
    "with open(\"dimension_analysis_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(dimension_analysis_pass_at_k, f)\n",
    "with open(\"explicit_math_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(explicit_math_pass_at_k, f)\n",
    "with open(\"part_whole_pass_at_k.pkl\", \"wb\") as f:\n",
    "    pickle.dump(part_whole_pass_at_k, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for gpt-j\n",
    "#config = lu.gptj_gen_args()\n",
    "\n",
    "#tu.set_all_seeds(model_name)\n",
    "#hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config, print_output=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.12.15 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/PracticalWork2021/wandb/run-20220422_152055-3qt35mwp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/antoniolopardo/PracticalWork/runs/3qt35mwp\" target=\"_blank\">@100-codegen-0</a></strong> to <a href=\"https://wandb.ai/antoniolopardo/PracticalWork\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTESTING STARTED\u001b[0m\n",
      "\u001b[37m@sample 5 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 10 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 15 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 20 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 25 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 30 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 35 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 40 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 45 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 50 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 55 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 60 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 65 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 70 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 75 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 80 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 85 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 90 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 95 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[37m@sample 100 -> Pass@3 = 0.0\u001b[0m\n",
      "\u001b[32m\n",
      "\n",
      "Pass@3 = 0.0\u001b[0m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c68ac0450d44e6a223f46692d65da1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pass_at_k</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pass_at_k</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">@100-codegen-0</strong>: <a href=\"https://wandb.ai/antoniolopardo/PracticalWork/runs/3qt35mwp\" target=\"_blank\">https://wandb.ai/antoniolopardo/PracticalWork/runs/3qt35mwp</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220422_152055-3qt35mwp/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with wandb.init(project=\"PracticalWork\", entity=\"antoniolopardo\",config=config, name=wandb_run_name):\n",
    "\n",
    "        tu.set_all_seeds(model_name)\n",
    "        pass_at_k, _ = tu.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config, func_def_mod=True, print_output=False)\n",
    "\n",
    "        wandb.log({\"pass_at_k\": pass_at_k})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ea8e8bf8ca3b9f65e7cf95ea2223aa98d68a16922d567d33b86408fe49c3092"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('HFtests': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
