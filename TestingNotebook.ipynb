{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(os.path.join(cur_dir, 'data'))\n",
    "!git clone https://gitlab.cs.washington.edu/ALGES/TACL2015.git\n",
    "!git clone https://github.com/chaochun/nlu-asdiv-dataset.git\n",
    "!git clone https://github.com/openai/grade-school-math.git\n",
    "os.chdir(cur_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "fatal: destination path 'TACL2015' already exists and is not an empty directory.\n",
      "fatal: destination path 'nlu-asdiv-dataset' already exists and is not an empty directory.\n",
      "fatal: destination path 'grade-school-math' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from xml.etree import ElementTree\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "from termcolor import colored\n",
    "import wandb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "def set_all_seeds():\n",
    "    \"\"\"Set all seeds\"\"\"\n",
    "    torch.manual_seed(0)\n",
    "    np.random.seed(8)\n",
    "    os.environ['PYTHONHASHSEED']=str(0)\n",
    "    #torch.backends.cudnn.deterministic = True\n",
    "    #torch.backends.cudnn.benchmark = False\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import dataset_handler as dh\n",
    "import helper_func as hf\n",
    "\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\"\"\"Load gsm8k\"\"\"\n",
    "priming_text_path = \"data/priming_texts/gsm8k/gsm8k_fewer_alt_codegen.txt\"\n",
    "current_dataset = dh.init_dataset_from_name(\"gsm8k\", primingtext_path = priming_text_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "\"\"\"Load asdiv\"\"\"\n",
    "priming_text_path = \"data/priming_texts/asdiv/asdiv_prefix_codegen.txt\"\n",
    "current_dataset = dh.init_dataset_from_name(\"asdiv\", primingtext_path = priming_text_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "set_all_seeds()\n",
    "\n",
    "sample_q_list, sample_a_list = current_dataset.sample_n_for_prompting(50)\n",
    "\n",
    "print(colored(sample_q_list[0], \"blue\"))\n",
    "print(colored(sample_a_list[0], \"green\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[34mWrite a program that prints the answer to the following question. When they got there, they saw that SFL is already filled with people. Every entrance has a long line, with 283 people waiting to get in. If SFL has 5 entrances, how many people in total are waiting to get in?\u001b[0m\n",
      "\u001b[32m1415 (people)\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "\"\"\"CodeGen runs in the venv venv\"\"\"\n",
    "model_args = hf.model_args()\n",
    "model, tokenizer = hf.load_CodeGen(model_args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading parameters\n",
      "loading parameters took 478.78s\n",
      "loading tokenizer\n",
      "loading tokenizer took 4.02s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"GPT-J and codeparrot models run in HFTest venv\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(gptj_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(gptj_model).half().eval().cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "gen_args = hf.codegen_gen_args()\n",
    "gen_args.num_return_sequences = 5\n",
    "gen_args.k = 3\n",
    "gen_args.max_lenght_after_input = 250\n",
    "gen_args.top_p = 1\n",
    "gen_args.top_k = 200\n",
    "gen_args.temperature = 0.7\n",
    "\n",
    "\n",
    "set_all_seeds()\n",
    "hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, gen_args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mTESTING STARTED\u001b[0m\n",
      "\u001b[37m@sample 5 -> Pass@3 = 0.4\u001b[0m\n",
      "\u001b[37m@sample 10 -> Pass@3 = 0.44000000000000006\u001b[0m\n",
      "\u001b[32m\n",
      "\n",
      "Pass@3 = 0.44000000000000006\u001b[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.44000000000000006"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "config = hf.codegen_gen_args()\n",
    "config.num_return_sequences = 5\n",
    "config.k = 3\n",
    "config.max_lenght_after_input = 250\n",
    "config.top_p = 1\n",
    "config.top_k = 50\n",
    "config.temperature = 0.7\n",
    "\n",
    "with wandb.init(project=\"PracticalWork\", entity=\"antoniolopardo\",config=config, name=\"@50-mid-top_k-codegen\"):\n",
    "\n",
    "        set_all_seeds()\n",
    "        pass_at_k = hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config)\n",
    "\n",
    "        wandb.log({\"pass_at_k\": pass_at_k})"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/PracticalWork2021/wandb/run-20220404_105343-3co89cj5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/antoniolopardo/PracticalWork/runs/3co89cj5\" target=\"_blank\">@50-mid-top_k-codegen</a></strong> to <a href=\"https://wandb.ai/antoniolopardo/PracticalWork\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mTESTING STARTED\u001b[0m\n",
      "\u001b[37m@sample 5 -> Pass@3 = 0.4\u001b[0m\n",
      "\u001b[37m@sample 10 -> Pass@3 = 0.44000000000000006\u001b[0m\n",
      "\u001b[37m@sample 15 -> Pass@3 = 0.4571428571428572\u001b[0m\n",
      "\u001b[37m@sample 20 -> Pass@3 = 0.4526315789473684\u001b[0m\n",
      "\u001b[37m@sample 25 -> Pass@3 = 0.4791666666666667\u001b[0m\n",
      "\u001b[37m@sample 30 -> Pass@3 = 0.496551724137931\u001b[0m\n",
      "\u001b[37m@sample 35 -> Pass@3 = 0.47941176470588226\u001b[0m\n",
      "\u001b[37m@sample 40 -> Pass@3 = 0.5179487179487179\u001b[0m\n",
      "\u001b[37m@sample 45 -> Pass@3 = 0.5022727272727272\u001b[0m\n",
      "\u001b[37m@sample 50 -> Pass@3 = 0.4755102040816327\u001b[0m\n",
      "\u001b[32m\n",
      "\n",
      "Pass@3 = 0.4755102040816327\u001b[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5b2a39910224bc9a9a2818c8d3a00eb"
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pass_at_k</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pass_at_k</td><td>0.47551</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">@50-mid-top_k-codegen</strong>: <a href=\"https://wandb.ai/antoniolopardo/PracticalWork/runs/3co89cj5\" target=\"_blank\">https://wandb.ai/antoniolopardo/PracticalWork/runs/3co89cj5</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220404_105343-3co89cj5/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('HFtests': venv)"
  },
  "interpreter": {
   "hash": "5ea8e8bf8ca3b9f65e7cf95ea2223aa98d68a16922d567d33b86408fe49c3092"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}