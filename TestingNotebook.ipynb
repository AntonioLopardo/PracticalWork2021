{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(os.path.join(cur_dir, 'data'))\n",
    "!git clone https://gitlab.cs.washington.edu/ALGES/TACL2015.git\n",
    "!git clone https://github.com/chaochun/nlu-asdiv-dataset.git\n",
    "!git clone https://github.com/openai/grade-school-math.git\n",
    "os.chdir(cur_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'TACL2015'...\n",
      "remote: Enumerating objects: 2294, done.\u001b[K\n",
      "remote: Counting objects: 100% (2294/2294), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2234/2234), done.\u001b[K\n",
      "remote: Total 2294 (delta 203), reused 2103 (delta 55), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (2294/2294), 4.51 MiB | 3.62 MiB/s, done.\n",
      "Resolving deltas: 100% (203/203), done.\n",
      "Cloning into 'nlu-asdiv-dataset'...\n",
      "remote: Enumerating objects: 30, done.\u001b[K\n",
      "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
      "remote: Compressing objects: 100% (20/20), done.\u001b[K\n",
      "remote: Total 30 (delta 6), reused 20 (delta 5), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (30/30), 425.56 KiB | 1.67 MiB/s, done.\n",
      "Cloning into 'grade-school-math'...\n",
      "remote: Enumerating objects: 36, done.\u001b[K\n",
      "remote: Counting objects: 100% (36/36), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 36 (delta 14), reused 30 (delta 11), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (36/36), 3.01 MiB | 4.94 MiB/s, done.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "from xml.etree import ElementTree\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "from termcolor import colored\n",
    "import wandb"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import dataset_handler as dh\n",
    "import helper_func as hf\n",
    "\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\"\n",
    "\n",
    "#model_name = \"gpt-j\"\n",
    "model_name = \"codegen\"\n",
    "\n",
    "#dataset_name = \"gsm8k\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import exp_impl.func_def_eq as exp_impl\n",
    "#import exp_impl.func_def_mine as exp_impl\n",
    "#import exp_impl.simple_func_def as exp_impl"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "import importlib\n",
    "importlib.reload(exp_impl)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<module 'exp_impl.func_def_eq' from '/home/PracticalWork2021/exp_impl/func_def_eq.py'>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "\"\"\"Load gsm8k\"\"\"\n",
    "\n",
    "if model_name == \"gpt-j\":\n",
    "    priming_text_path = (\n",
    "        \"data/priming_texts/gsm8k/gpt-j/gsm8k_fewer_alt.txt\"  # for gpt-j\n",
    "    )\n",
    "    current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\", primingtext_path=priming_text_path\n",
    "    )\n",
    "else:\n",
    "    priming_text_path = \"data/priming_texts/gsm8k/codegen/gsm8k_fewer_alt_codegen_func_eq.txt\"  # for codegen\n",
    "    #priming_text_path = \"data/priming_texts/gsm8k/codegen/gsm8k_fewer_alt_codegen_func.txt\"\n",
    "    current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\",\n",
    "        primingtext_path=priming_text_path,\n",
    "        sample_func=exp_impl.sample_n_for_prompting,\n",
    "        generate_prompt_func=exp_impl.generate_prompt,\n",
    "    )\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "\"\"\"Load asdiv\"\"\"\n",
    "\n",
    "if model_name == \"gpt-j\":\n",
    "    priming_text_path = \"data/priming_texts/asdiv/asdiv_prefix.txt\" # for gpt-j\n",
    "else:\n",
    "    priming_text_path = \"data/priming_texts/asdiv/asdiv_prefix_codegen.txt\" # for codegen\n",
    "\n",
    "current_dataset = dh.init_dataset_from_name(\"asdiv\", primingtext_path = priming_text_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "hf.set_all_seeds()\n",
    "\n",
    "sample_q_list, sample_a_list = current_dataset.sample_n_for_prompting(500)\n",
    "\n",
    "print(colored(sample_q_list[0], \"blue\"))\n",
    "print(colored(sample_a_list[0], \"green\"))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[34mdef exercise6():\n",
      "    \"\"\"Carol sells tickets for an exhibition. During three days she sold tickets worth $960. One ticket costs $4. How many tickets on average did she sell during one of these three days? Hint: use these equations eq1: 960/4=240 eq2: 240/3=80\"\"\"\u001b[0m\n",
      "\u001b[32m80\u001b[0m\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "with open(\"test_prompt.txt\", \"w\") as f:\n",
    "    f.write(current_dataset.generate_prompt(sample_q_list[0]))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "if model_name == \"gpt-j\":\n",
    "    \"\"\"GPT-J and codeparrot models run in HFTest venv\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(gptj_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(gptj_model).half().eval().cuda()\n",
    "elif model_name == \"codegen\":\n",
    "    \"\"\"CodeGen runs in the venv venv\"\"\"\n",
    "    model_args = hf.model_args()\n",
    "    #model_args.model = \"codegen-350M-mono\"\n",
    "    model, tokenizer = hf.load_CodeGen(model_args)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loading parameters\n",
      "loading parameters took 426.86s\n",
      "loading tokenizer\n",
      "loading tokenizer took 4.04s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "# Set up for CodeGen\n",
    "config = hf.codegen_gen_args()\n",
    "config.num_return_sequences = 4 # 4 for gsm8k 5 for asdiv\n",
    "config.k = 3\n",
    "config.max_lenght_after_input = 250\n",
    "config.top_p = 0.95\n",
    "config.top_k = 50\n",
    "config.temperature = 0.7\n",
    "config.min_length = 3\n",
    "\n",
    "hf.set_all_seeds(model_name)\n",
    "#hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config, func_def_mod=True, print_output=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Set up for gpt-j\n",
    "config = hf.gptj_gen_args()\n",
    "\n",
    "hf.set_all_seeds(model_name)\n",
    "#hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config, print_output=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "with wandb.init(project=\"PracticalWork\", entity=\"antoniolopardo\",config=config, name=\"@500-gsm8k-codegen-func-def-eq\"):\n",
    "\n",
    "        hf.set_all_seeds(model)\n",
    "        pass_at_k = hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config, func_def_mod=True, print_output=False)\n",
    "\n",
    "        wandb.log({\"pass_at_k\": pass_at_k})"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "wandb version 0.12.14 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/PracticalWork2021/wandb/run-20220412_193108-2sa2babr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/antoniolopardo/PracticalWork/runs/2sa2babr\" target=\"_blank\">@500-gsm8k-codegen-func-def-eq</a></strong> to <a href=\"https://wandb.ai/antoniolopardo/PracticalWork\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[33mTESTING STARTED\u001b[0m\n",
      "\u001b[37m@sample 5 -> Pass@3 = 0.45\u001b[0m\n",
      "\u001b[37m@sample 10 -> Pass@3 = 0.4\u001b[0m\n",
      "\u001b[37m@sample 15 -> Pass@3 = 0.26666666666666666\u001b[0m\n",
      "\u001b[37m@sample 20 -> Pass@3 = 0.325\u001b[0m\n",
      "\u001b[37m@sample 25 -> Pass@3 = 0.32\u001b[0m\n",
      "\u001b[37m@sample 30 -> Pass@3 = 0.26666666666666666\u001b[0m\n",
      "\u001b[37m@sample 35 -> Pass@3 = 0.32857142857142857\u001b[0m\n",
      "\u001b[37m@sample 40 -> Pass@3 = 0.3125\u001b[0m\n",
      "\u001b[37m@sample 45 -> Pass@3 = 0.31666666666666665\u001b[0m\n",
      "\u001b[37m@sample 50 -> Pass@3 = 0.32\u001b[0m\n",
      "\u001b[37m@sample 55 -> Pass@3 = 0.32272727272727275\u001b[0m\n",
      "\u001b[37m@sample 60 -> Pass@3 = 0.325\u001b[0m\n",
      "\u001b[37m@sample 65 -> Pass@3 = 0.3153846153846154\u001b[0m\n",
      "\u001b[37m@sample 70 -> Pass@3 = 0.3142857142857143\u001b[0m\n",
      "\u001b[37m@sample 75 -> Pass@3 = 0.33\u001b[0m\n",
      "\u001b[37m@sample 80 -> Pass@3 = 0.328125\u001b[0m\n",
      "\u001b[37m@sample 85 -> Pass@3 = 0.3264705882352941\u001b[0m\n",
      "\u001b[37m@sample 90 -> Pass@3 = 0.30833333333333335\u001b[0m\n",
      "\u001b[37m@sample 95 -> Pass@3 = 0.31842105263157894\u001b[0m\n",
      "\u001b[37m@sample 100 -> Pass@3 = 0.3025\u001b[0m\n",
      "\u001b[37m@sample 105 -> Pass@3 = 0.32857142857142857\u001b[0m\n",
      "\u001b[37m@sample 110 -> Pass@3 = 0.3386363636363636\u001b[0m\n",
      "\u001b[37m@sample 115 -> Pass@3 = 0.3239130434782609\u001b[0m\n",
      "\u001b[37m@sample 120 -> Pass@3 = 0.31666666666666665\u001b[0m\n",
      "\u001b[37m@sample 125 -> Pass@3 = 0.318\u001b[0m\n",
      "\u001b[37m@sample 130 -> Pass@3 = 0.3211538461538462\u001b[0m\n",
      "\u001b[37m@sample 135 -> Pass@3 = 0.30925925925925923\u001b[0m\n",
      "\u001b[37m@sample 140 -> Pass@3 = 0.3053571428571429\u001b[0m\n",
      "\u001b[37m@sample 145 -> Pass@3 = 0.3\u001b[0m\n",
      "\u001b[37m@sample 150 -> Pass@3 = 0.30333333333333334\u001b[0m\n",
      "\u001b[37m@sample 155 -> Pass@3 = 0.29354838709677417\u001b[0m\n",
      "\u001b[37m@sample 160 -> Pass@3 = 0.2953125\u001b[0m\n",
      "\u001b[37m@sample 165 -> Pass@3 = 0.296969696969697\u001b[0m\n",
      "\u001b[37m@sample 170 -> Pass@3 = 0.29705882352941176\u001b[0m\n",
      "\u001b[37m@sample 175 -> Pass@3 = 0.3\u001b[0m\n",
      "\u001b[37m@sample 180 -> Pass@3 = 0.2916666666666667\u001b[0m\n",
      "\u001b[37m@sample 185 -> Pass@3 = 0.28783783783783784\u001b[0m\n",
      "\u001b[37m@sample 190 -> Pass@3 = 0.29078947368421054\u001b[0m\n",
      "\u001b[37m@sample 195 -> Pass@3 = 0.2935897435897436\u001b[0m\n",
      "\u001b[37m@sample 200 -> Pass@3 = 0.29125\u001b[0m\n",
      "\u001b[37m@sample 205 -> Pass@3 = 0.2939024390243902\u001b[0m\n",
      "\u001b[37m@sample 210 -> Pass@3 = 0.2916666666666667\u001b[0m\n",
      "\u001b[37m@sample 215 -> Pass@3 = 0.29186046511627906\u001b[0m\n",
      "\u001b[37m@sample 220 -> Pass@3 = 0.2988636363636364\u001b[0m\n",
      "\u001b[37m@sample 225 -> Pass@3 = 0.30333333333333334\u001b[0m\n",
      "\u001b[37m@sample 230 -> Pass@3 = 0.30869565217391304\u001b[0m\n",
      "\u001b[37m@sample 235 -> Pass@3 = 0.31382978723404253\u001b[0m\n",
      "\u001b[37m@sample 240 -> Pass@3 = 0.315625\u001b[0m\n",
      "\u001b[37m@sample 245 -> Pass@3 = 0.31326530612244896\u001b[0m\n",
      "\u001b[37m@sample 250 -> Pass@3 = 0.311\u001b[0m\n",
      "\u001b[37m@sample 255 -> Pass@3 = 0.307843137254902\u001b[0m\n",
      "\u001b[37m@sample 260 -> Pass@3 = 0.3057692307692308\u001b[0m\n",
      "\u001b[37m@sample 265 -> Pass@3 = 0.3132075471698113\u001b[0m\n",
      "\u001b[37m@sample 270 -> Pass@3 = 0.3111111111111111\u001b[0m\n",
      "\u001b[37m@sample 275 -> Pass@3 = 0.3090909090909091\u001b[0m\n",
      "\u001b[37m@sample 280 -> Pass@3 = 0.30892857142857144\u001b[0m\n",
      "\u001b[37m@sample 285 -> Pass@3 = 0.30701754385964913\u001b[0m\n",
      "\u001b[37m@sample 290 -> Pass@3 = 0.3017241379310345\u001b[0m\n",
      "\u001b[37m@sample 295 -> Pass@3 = 0.29915254237288136\u001b[0m\n",
      "\u001b[37m@sample 300 -> Pass@3 = 0.2966666666666667\u001b[0m\n",
      "\u001b[37m@sample 305 -> Pass@3 = 0.2942622950819672\u001b[0m\n",
      "\u001b[37m@sample 310 -> Pass@3 = 0.29274193548387095\u001b[0m\n",
      "\u001b[37m@sample 315 -> Pass@3 = 0.29444444444444445\u001b[0m\n",
      "\u001b[37m@sample 320 -> Pass@3 = 0.2921875\u001b[0m\n",
      "\u001b[37m@sample 325 -> Pass@3 = 0.29307692307692307\u001b[0m\n",
      "\u001b[37m@sample 330 -> Pass@3 = 0.296969696969697\u001b[0m\n",
      "\u001b[37m@sample 335 -> Pass@3 = 0.29776119402985074\u001b[0m\n",
      "\u001b[37m@sample 340 -> Pass@3 = 0.2985294117647059\u001b[0m\n",
      "\u001b[37m@sample 345 -> Pass@3 = 0.2971014492753623\u001b[0m\n",
      "\u001b[37m@sample 350 -> Pass@3 = 0.29285714285714287\u001b[0m\n",
      "\u001b[37m@sample 355 -> Pass@3 = 0.2908450704225352\u001b[0m\n",
      "\u001b[37m@sample 360 -> Pass@3 = 0.28888888888888886\u001b[0m\n",
      "\u001b[37m@sample 365 -> Pass@3 = 0.2876712328767123\u001b[0m\n",
      "\u001b[37m@sample 370 -> Pass@3 = 0.28783783783783784\u001b[0m\n",
      "\u001b[37m@sample 375 -> Pass@3 = 0.2926666666666667\u001b[0m\n",
      "\u001b[37m@sample 380 -> Pass@3 = 0.29539473684210527\u001b[0m\n",
      "\u001b[37m@sample 385 -> Pass@3 = 0.2987012987012987\u001b[0m\n",
      "\u001b[37m@sample 390 -> Pass@3 = 0.2987179487179487\u001b[0m\n",
      "\u001b[37m@sample 395 -> Pass@3 = 0.2993670886075949\u001b[0m\n",
      "\u001b[37m@sample 400 -> Pass@3 = 0.300625\u001b[0m\n",
      "\u001b[37m@sample 405 -> Pass@3 = 0.29876543209876544\u001b[0m\n",
      "\u001b[37m@sample 410 -> Pass@3 = 0.2951219512195122\u001b[0m\n",
      "\u001b[37m@sample 415 -> Pass@3 = 0.2933734939759036\u001b[0m\n",
      "\u001b[37m@sample 420 -> Pass@3 = 0.29642857142857143\u001b[0m\n",
      "\u001b[37m@sample 425 -> Pass@3 = 0.2952941176470588\u001b[0m\n",
      "\u001b[37m@sample 430 -> Pass@3 = 0.2988372093023256\u001b[0m\n",
      "\u001b[37m@sample 435 -> Pass@3 = 0.3022988505747126\u001b[0m\n",
      "\u001b[37m@sample 440 -> Pass@3 = 0.30511363636363636\u001b[0m\n",
      "\u001b[37m@sample 445 -> Pass@3 = 0.30730337078651687\u001b[0m\n",
      "\u001b[37m@sample 450 -> Pass@3 = 0.30777777777777776\u001b[0m\n",
      "\u001b[37m@sample 455 -> Pass@3 = 0.3087912087912088\u001b[0m\n",
      "\u001b[37m@sample 460 -> Pass@3 = 0.3114130434782609\u001b[0m\n",
      "\u001b[37m@sample 465 -> Pass@3 = 0.31451612903225806\u001b[0m\n",
      "\u001b[37m@sample 470 -> Pass@3 = 0.31648936170212766\u001b[0m\n",
      "\u001b[37m@sample 475 -> Pass@3 = 0.31473684210526315\u001b[0m\n",
      "\u001b[37m@sample 480 -> Pass@3 = 0.31979166666666664\u001b[0m\n",
      "\u001b[37m@sample 485 -> Pass@3 = 0.32216494845360827\u001b[0m\n",
      "\u001b[37m@sample 490 -> Pass@3 = 0.32040816326530613\u001b[0m\n",
      "\u001b[37m@sample 495 -> Pass@3 = 0.3237373737373737\u001b[0m\n",
      "\u001b[37m@sample 500 -> Pass@3 = 0.322\u001b[0m\n",
      "\u001b[32m\n",
      "\n",
      "Pass@3 = 0.322\u001b[0m\n",
      "\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4dc126d595204eb9a8d7b8290621a4f1"
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>pass_at_k</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>pass_at_k</td><td>0.322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">@500-gsm8k-codegen-func-def-eq</strong>: <a href=\"https://wandb.ai/antoniolopardo/PracticalWork/runs/2sa2babr\" target=\"_blank\">https://wandb.ai/antoniolopardo/PracticalWork/runs/2sa2babr</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220412_193108-2sa2babr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('HFtests': venv)"
  },
  "interpreter": {
   "hash": "5ea8e8bf8ca3b9f65e7cf95ea2223aa98d68a16922d567d33b86408fe49c3092"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}