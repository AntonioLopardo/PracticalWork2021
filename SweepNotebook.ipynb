{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\n",
    "from xml.etree import ElementTree\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from io import StringIO\n",
    "from contextlib import redirect_stdout\n",
    "from termcolor import colored"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import dataset_handler as dh\n",
    "import helper_func as hf"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(8)\n",
    "\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\"\n",
    "\n",
    "\"\"\"Load the priming text to add to the prompt and sample a question\"\"\"\n",
    "# priming_text_path = \"data/priming_texts/gsm8k/gsm8k_fewer_alt_codegen.txt\"\n",
    "# priming_text = read_string_from_file(\"data/priming_texts/singleEq.txt\")\n",
    "priming_text_path = \"data/priming_texts/asdiv/asdiv_prefix_codegen.txt\"\n",
    "\n",
    "current_dataset = dh.init_dataset_from_name(\"asdiv\", primingtext_path = priming_text_path)\n",
    "\n",
    "sample_q_list, sample_a_list = current_dataset.sample_n_for_prompting(10)\n",
    "\n",
    "print(colored(sample_q_list[0], \"blue\"))\n",
    "print(colored(sample_a_list[0], \"green\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\"CodeGen runs in the venv venv\"\"\"\n",
    "model_args = hf.model_args()\n",
    "model, tokenizer = hf.load_CodeGen(model_args)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "\n",
    "        pass_at_k = hf.testing_loop(current_dataset, tokenizer, model, sample_q_list, sample_a_list, config)\n",
    "\n",
    "        wandb.log({\"pass_at_k\": pass_at_k})"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sweep_config = {\n",
    "    'method': 'random'\n",
    "    }\n",
    "\n",
    "metric = {\n",
    "    'name': 'pass_at_k',\n",
    "    'goal': 'maximize'   \n",
    "    }\n",
    "\n",
    "sweep_config['metric'] = metric\n",
    "\n",
    "parameters_dict = {\n",
    "    'k': {\n",
    "        'values': 3\n",
    "        },\n",
    "    'do_sample': {\n",
    "        'values': True\n",
    "        },\n",
    "    'top_k': {\n",
    "          'values': [10, 1, 50, 100]\n",
    "        },\n",
    "    'temperature': {\n",
    "          'values': [0.0, 0.2, 0.5, 0.9]\n",
    "        },\n",
    "    'min_length': {\n",
    "          'values': 1\n",
    "        },\n",
    "    'max_length_after_input': {\n",
    "          'values': [100, 200, 250]\n",
    "        },\n",
    "    'num_return_sequences': {\n",
    "          'values': 3\n",
    "        },\n",
    "    }\n",
    "\n",
    "sweep_config['parameters'] = parameters_dict"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=\"PracticalWork\")\n",
    "wandb.agent(sweep_id, test, count=5)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}