{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CodeGen_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "from termcolor import colored\n",
    "import wandb\n",
    "import importlib\n",
    "import re\n",
    "\n",
    "import dataset_handler as dh\n",
    "import loading_utils as lu\n",
    "import testing_utils as tu\n",
    "\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\"\n",
    "\n",
    "#model_name = \"gpt-j\"\n",
    "model_name = \"codegen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dataset_handler' from '/home/PracticalWork2021/dataset_handler.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(dh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading parameters\n",
      "loading parameters took 469.87s\n",
      "loading tokenizer\n",
      "loading tokenizer took 3.98s\n"
     ]
    }
   ],
   "source": [
    "transformers.set_seed(5)\n",
    "if model_name == \"gpt-j\":\n",
    "    \"\"\"GPT-J and codeparrot models run in HFTest venv\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(gptj_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(gptj_model).half().eval().cuda()\n",
    "elif model_name == \"codegen\":\n",
    "    \"\"\"CodeGen runs in the venv venv\"\"\"\n",
    "    model_args = lu.model_args()\n",
    "    #model_args.model = \"codegen-350M-mono\"\n",
    "    model, tokenizer = lu.load_CodeGen(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdef exercise4():\n",
      "    \"\"\"\n",
      "    Carol sells tickets for an exhibition. During three days she sold tickets worth $960. One ticket costs $4.\n",
      "    \"\"\"\u001b[0m\n",
      "\u001b[32m80\u001b[0m\n",
      "\u001b[33m[' How many tickets did Carol sell during three days?\\n    Use no more than 2 variables', ' How many tickets did Carol sell on average in one day?\\n    Use no more than 4 variables']\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#import exp_impl.func_def_general_socratic as exp_impl\n",
    "import exp_impl.func_def_general_socratic_variable_hint as exp_impl\n",
    "\n",
    "priming_text_path = \"data/priming_texts/gsm8k/socratic/var_hint/func_def_socratic_step1.txt\"\n",
    "importlib.reload(exp_impl)\n",
    "\n",
    "priming_text_dir = \"data/priming_texts/gsm8k/socratic/var_hint/\"\n",
    "\n",
    "priming_text_paths_list = os.listdir(priming_text_dir)\n",
    "priming_text_paths_list.sort()\n",
    "\n",
    "\"\"\"Load gsm8k\"\"\"\n",
    "\n",
    "current_dataset = dh.init_dataset_from_name(\n",
    "    \"gsm8k-socratic\",\n",
    "    primingtext_path=priming_text_path,\n",
    "    sample_func=exp_impl.sample_n_for_prompting,\n",
    "    generate_prompt_func=exp_impl.generate_prompt,\n",
    ")\n",
    "\n",
    "tu.set_all_seeds()\n",
    "\n",
    "sample_q_list, sample_steps_list, sample_a_list = current_dataset.sample_n_for_prompting(100, inc_eq=False)\n",
    "\n",
    "with open(\"test_prompt_gen.txt\", \"w\") as f:\n",
    "    f.write(current_dataset.generate_prompt(sample_q_list[0]))\n",
    "\n",
    "print(colored(sample_q_list[0], \"blue\"))\n",
    "print(colored(sample_a_list[0], \"green\"))\n",
    "print(colored(sample_steps_list[0], \"yellow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_last_question(current_prompt):\n",
    "    temp_list = current_prompt.split('\"\"\"')\n",
    "\n",
    "    sample_q = temp_list[-2]\n",
    "\n",
    "    comma_list_senteces = sample_q.split(\",\")\n",
    "    period_list_senteces = sample_q.split(\".\")\n",
    "\n",
    "    if len(comma_list_senteces[-1]) > len(period_list_senteces[-1]):\n",
    "        sample_q = sample_q[: -len(period_list_senteces[-1])] + \"\\n    \"\n",
    "    else:\n",
    "        sample_q = sample_q[: -len(comma_list_senteces[-1])] + \"\\n    \"\n",
    "\n",
    "    temp_list[-2] = sample_q\n",
    "\n",
    "    return '\"\"\"'.join(temp_list)\n",
    "\n",
    "\n",
    "def add_step_to_sample(current_prompt, step_q):\n",
    "    temp_list = current_prompt.split('\"\"\"')\n",
    "\n",
    "    if temp_list[-2][-6] == \".\":\n",
    "        temp_list[-2] = temp_list[-2][:-5] + step_q\n",
    "    else:\n",
    "        str_list = list(step_q)\n",
    "        str_list[1] = step_q[1].lower()\n",
    "        step_q = \"\".join(str_list)\n",
    "        temp_list[-2] = temp_list[-2][:-5] + step_q\n",
    "\n",
    "    return '\"\"\"'.join(temp_list)\n",
    "\n",
    "def change_prompt_for_next_step(current_prompt, current_step):\n",
    "    #print(colored(priming_text_paths_list[current_step+1], \"blue\"))\n",
    "    if current_step > 3:\n",
    "        current_step = 3\n",
    "    with open(os.path.join(priming_text_dir, priming_text_paths_list[current_step+1]), \"r\") as f:\n",
    "        current_priming_text = f.read()\n",
    "\n",
    "    return current_priming_text + \"\\n\\n\" + \"def exercise4\" + current_prompt.split(\"def exercise4\")[-1]\n",
    "\n",
    "def preproc_gen_toks(gen_toks, input_len, tokenizer, last=False):\n",
    "    for gen_tok in gen_toks:\n",
    "        last_tokens = gen_tok[input_len:]\n",
    "        generated_text = tokenizer.decode(last_tokens)\n",
    "        with open(\"test_preproc_gen_tokens.txt\", \"a\") as f:\n",
    "            f.write(generated_text)\n",
    "\n",
    "    if last:\n",
    "        return tu.preproc_gen_toks(gen_toks, input_len, tokenizer, func_def_mod=True)\n",
    "    return [generated_text.split(\"return \")[0][:-5]]\n",
    "\n",
    "from wrapt_timeout_decorator import *\n",
    "\n",
    "@timeout(45)\n",
    "def execute(c):\n",
    "    exec(c, globals())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for CodeGen\n",
    "config = lu.codegen_gen_args()\n",
    "config.num_return_sequences = 1\n",
    "config.max_length_after_input = 60\n",
    "config.top_p = 0.8\n",
    "config.top_k = 30\n",
    "#config.temperature = 0.7\n",
    "config.temperature = 1\n",
    "config.min_length = 1\n",
    "\n",
    "gen_args = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "invalid syntax (<string>, line 52)\n",
      "name 'articles_per_da_e' is not defined\n",
      "Up to sample 10: 0.2\n",
      "invalid syntax (<string>, line 65)\n",
      "name 'nr_maogoes' is not defined\n",
      "invalid syntax (<string>, line 40)\n",
      "invalid syntax (<string>, line 59)\n",
      "Up to sample 20: 0.1\n",
      "invalid syntax (<string>, line 44)\n",
      "invalid syntax (<string>, line 55)\n",
      "name 'ticket_cost_fris_wheel' is not defined\n",
      "Up to sample 30: 0.06666666666666667\n",
      "name 'nr_woens' is not defined\n",
      "invalid syntax (<string>, line 40)\n",
      "invalid syntax (<string>, line 43)\n",
      "invalid syntax (<string>, line 55)\n",
      "invalid syntax (<string>, line 56)\n",
      "\u001b[31mError in add_step_to_sample\u001b[0m\n",
      "\u001b[31m39\u001b[0m\n",
      "invalid syntax (<string>, line 62)\n",
      "Up to sample 40: 0.05\n",
      "invalid syntax (<string>, line 59)\n",
      "name 'nr_blocks_to_gallary' is not defined\n",
      "Up to sample 50: 0.12\n",
      "name 'cpus_sales' is not defined\n",
      "name 'nr_of_ducks_per_year_afrer_5_years_and_150_ducks_and_100_ducks' is not defined\n",
      "Up to sample 60: 0.1\n",
      "name 'gas_statio_4' is not defined\n",
      "Up to sample 70: 0.11428571428571428\n",
      "\u001b[31mError in add_step_to_sample\u001b[0m\n",
      "\u001b[31m73\u001b[0m\n",
      "invalid syntax (<string>, line 62)\n",
      "Up to sample 80: 0.1125\n",
      "name 'house_worth_after_one_yea' is not defined\n",
      "\u001b[31mError in add_step_to_sample\u001b[0m\n",
      "\u001b[31m84\u001b[0m\n",
      "name 'nr_of_collected_papers_in_week' is not defined\n",
      "Up to sample 90: 0.1\n",
      "name 'nr_of_steps_in_minutes' is not defined\n",
      "invalid syntax (<string>, line 49)\n",
      "name 'nr_points_to_break_recor_per_player' is not defined\n",
      "invalid syntax (<string>, line 44)\n",
      "Up to sample 100: 0.11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.11"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.set_seed(5)\n",
    "pass_1_list = []\n",
    "cnt = 0\n",
    "for sample_q, sample_a, sample_steps in zip(sample_q_list, sample_a_list, sample_steps_list):\n",
    "    cnt += 1\n",
    "    cp = current_dataset.generate_prompt(sample_q)\n",
    "    for i, step_q in enumerate(sample_steps):\n",
    "        is_last = (i == len(sample_steps) - 1)\n",
    "        try:\n",
    "            cp = add_step_to_sample(cp, step_q)\n",
    "        except:\n",
    "            print(colored(\"Error in add_step_to_sample\", \"red\"))\n",
    "            print(colored(cnt, \"red\"))\n",
    "            break\n",
    "        with open(\"test_prompt_gen.txt\", \"w\") as f:\n",
    "            f.write(cp)\n",
    "        #print(colored(f\"Step_{i+1}\", \"green\"))\n",
    "        tokens = tokenizer(cp, return_tensors=\"pt\").input_ids\n",
    "        generated_tokens = model.generate(\n",
    "            tokens.long().cuda(),\n",
    "            use_cache=True,\n",
    "            do_sample=False,\n",
    "            top_k=gen_args.top_k,\n",
    "            temperature=gen_args.temperature,\n",
    "            top_p=gen_args.top_p,\n",
    "            min_length=len(tokens[0]) + gen_args.min_length,\n",
    "            max_length=len(tokens[0]) + gen_args.max_length_after_input,\n",
    "            num_return_sequences=gen_args.num_return_sequences,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        list_outputs = preproc_gen_toks(\n",
    "            generated_tokens, len(tokens[0]), tokenizer, last=is_last\n",
    "        )\n",
    "\n",
    "        cp = cp + list_outputs[0]\n",
    "\n",
    "        if not is_last:\n",
    "            try:\n",
    "                cp = change_prompt_for_next_step(cp, i)\n",
    "                cp = remove_last_question(cp)\n",
    "            except:\n",
    "                print(colored(\"Error\", \"red\"))\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    try:\n",
    "        #print(prompt[re.search(print_pattern, prompt).start():])\n",
    "        execute(cp)\n",
    "        s = exercise4()\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        s = 1111111\n",
    "\n",
    "    pass_1_list.append(int(s == float(sample_a)))\n",
    "    if cnt % 10 == 0:\n",
    "        print(f\"Up to sample {cnt}: {np.mean(np.array(pass_1_list))}\")\n",
    "\n",
    "np.mean(np.array(pass_1_list))       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "376\n",
      "\n",
      "    nr_tickets = 960 * 3\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "prompt = current_dataset.generate_prompt(sample_q_list[0])\n",
    "prompt = add_step_to_sample(prompt, sample_steps_list[0][0])\n",
    "tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "generated_tokens = model.generate(\n",
    "    tokens.long().cuda(),\n",
    "    use_cache=True,\n",
    "    do_sample=False,\n",
    "    top_k=gen_args.top_k,\n",
    "    temperature=gen_args.temperature,\n",
    "    top_p=gen_args.top_p,\n",
    "    min_length=len(tokens[0]) + gen_args.min_length,\n",
    "    max_length=len(tokens[0]) + gen_args.max_length_after_input,\n",
    "    num_return_sequences=gen_args.num_return_sequences,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "list_outputs = preproc_gen_toks(\n",
    "    generated_tokens, len(tokens[0]), tokenizer\n",
    ")\n",
    "print(len(tokens[0]))\n",
    "print(len(tokens[0]) + gen_args.max_length_after_input)\n",
    "print(list_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80.0\n",
      "80.0\n",
      "7100.0\n",
      "7100.0\n",
      "name 'nr_rabbits_in_the_' is not defined\n",
      "invalid syntax (<string>, line 43)\n",
      "name 'suits_per_lily' is not defined\n",
      "name 'minutes_per_day' is not defined\n",
      "name 'tilling_length' is not defined\n",
      "unsupported operand type(s) for -: 'float' and 'list'\n",
      "73.0\n",
      "73.0\n",
      "name 'distance_between_kenn_and_' is not defined\n",
      "invalid syntax (<string>, line 42)\n",
      "1890\n",
      "1890.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.set_seed(5)\n",
    "pass_1_list = []\n",
    "\n",
    "for sample_q, sample_a in zip(sample_q_list[:50], sample_a_list[:50]):\n",
    "    prompt = current_dataset.generate_prompt(sample_q)\n",
    "\n",
    "    line_cnt = 0\n",
    "    print_pattern = re.compile(r\"def exercise4\")\n",
    "    while \"return \" not in prompt[re.search(print_pattern, prompt).start():] and line_cnt < 15:\n",
    "        line_cnt += 1\n",
    "        tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "        generated_tokens = model.generate(\n",
    "            tokens.long().cuda(),\n",
    "            use_cache=True,\n",
    "            do_sample=True,\n",
    "            top_k=gen_args.top_k,\n",
    "            temperature=gen_args.temperature,\n",
    "            top_p=gen_args.top_p,\n",
    "            min_length=len(tokens[0]) + gen_args.min_length,\n",
    "            max_length=len(tokens[0]) + gen_args.max_length_after_input,\n",
    "            num_return_sequences=gen_args.num_return_sequences,\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        list_outputs = preproc_gen_toks(\n",
    "            generated_tokens, len(tokens[0]), tokenizer\n",
    "        )\n",
    "        #print(len(tokens[0]))\n",
    "        #print(len(tokens[0]) + gen_args.max_length_after_input)\n",
    "        #print(list_outputs)\n",
    "\n",
    "        prompt += \"\\n\" + list_outputs\n",
    "\n",
    "\n",
    "        if \"return \" in prompt[re.search(print_pattern, prompt).start():]:\n",
    "            try:\n",
    "                #print(prompt[re.search(print_pattern, prompt).start():])\n",
    "                execute(prompt)\n",
    "                s = exercise4()\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                s = 1111111\n",
    "        #print(prompt)\n",
    "\n",
    "    pass_1_list.append(int(s == float(sample_a)))\n",
    "    if int(s == float(sample_a)) == 1:\n",
    "        print(s)\n",
    "        print(float(sample_a))\n",
    "\n",
    "np.mean(np.array(pass_1_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c59954e50921301bece1313ab371cee7cd99362dbd740142445e95aebb494b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('CodeGen_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
