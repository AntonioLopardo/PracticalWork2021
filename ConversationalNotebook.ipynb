{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import transformers\n",
    "from termcolor import colored\n",
    "import wandb\n",
    "import importlib\n",
    "import re\n",
    "\n",
    "import dataset_handler as dh\n",
    "import loading_utils as lu\n",
    "import testing_utils as tu\n",
    "\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\"\n",
    "\n",
    "#model_name = \"gpt-j\"\n",
    "model_name = \"codegen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading parameters\n",
      "loading parameters took 470.61s\n",
      "loading tokenizer\n",
      "loading tokenizer took 3.98s\n"
     ]
    }
   ],
   "source": [
    "transformers.set_seed(5)\n",
    "if model_name == \"gpt-j\":\n",
    "    \"\"\"GPT-J and codeparrot models run in HFTest venv\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(gptj_model)\n",
    "    model = AutoModelForCausalLM.from_pretrained(gptj_model).half().eval().cuda()\n",
    "elif model_name == \"codegen\":\n",
    "    \"\"\"CodeGen runs in the venv venv\"\"\"\n",
    "    model_args = lu.model_args()\n",
    "    #model_args.model = \"codegen-350M-mono\"\n",
    "    model, tokenizer = lu.load_CodeGen(model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mdef exercise4():\n",
      "    \"\"\"\n",
      "    Carol sells tickets for an exhibition. During three days she sold tickets worth $960. One ticket costs $4. How many tickets on average did she sell during one of these three days?\n",
      "    \"\"\"\u001b[0m\n",
      "\u001b[32m80\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#import exp_impl.eq_legacy.func_def_eq_short as exp_impl\n",
    "import exp_impl.func_def_general as exp_impl\n",
    "\n",
    "\n",
    "#priming_text_path = \"data/priming_texts/gsm8k/clustering_prompt/3_clusters/cluster_2.txt\"  # for codegen\n",
    "#priming_text_path = \"data/priming_texts/gsm8k/codegen/func_eq_short.txt\"\n",
    "priming_text_path = \"data/priming_texts/gsm8k/codegen/func_short.txt\"\n",
    "#priming_text_path = \"data/priming_texts/gsm8k/concepts_prompt/part-whole_3.txt\"\n",
    "#wandb_run_name = \"@100-codegen-0\"\n",
    "importlib.reload(exp_impl)\n",
    "\n",
    "\"\"\"Load gsm8k\"\"\"\n",
    "\n",
    "if model_name == \"gpt-j\":\n",
    "    priming_text_path = (\n",
    "        \"data/priming_texts/gsm8k/gpt-j/gsm8k_fewer_alt.txt\"  # for gpt-j\n",
    "    )\n",
    "    current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\", primingtext_path=priming_text_path\n",
    "    )\n",
    "else:\n",
    "    current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\",\n",
    "        primingtext_path=priming_text_path,\n",
    "        sample_func=exp_impl.sample_n_for_prompting,\n",
    "        generate_prompt_func=exp_impl.generate_prompt,\n",
    "    )\n",
    "\n",
    "tu.set_all_seeds()\n",
    "#tu.set_all_seeds_alt()\n",
    "\n",
    "sample_q_list, sample_a_list = current_dataset.sample_n_for_prompting(100, inc_eq=False)\n",
    "\n",
    "with open(\"test_prompt_gen.txt\", \"w\") as f:\n",
    "    f.write(current_dataset.generate_prompt(sample_q_list[0]))\n",
    "\n",
    "print(colored(sample_q_list[0], \"blue\"))\n",
    "print(colored(sample_a_list[0], \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up for CodeGen\n",
    "config = lu.codegen_gen_args()\n",
    "#config.num_return_sequences = 4 # 4 for gsm8k 5 for asdiv\n",
    "config.num_return_sequences = 1\n",
    "config.k = 3\n",
    "config.max_length_after_input = 30\n",
    "#config.top_p = 0.95\n",
    "config.top_p = 0.7\n",
    "config.top_k = 10\n",
    "#config.temperature = 0.7\n",
    "config.temperature = 1\n",
    "config.min_length = 1\n",
    "\n",
    "gen_args = config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproc_gen_toks(gen_toks, input_len, tokenizer):\n",
    "    print(len(gen_toks[0]))\n",
    "    for gen_tok in gen_toks:\n",
    "        last_tokens = gen_tok[input_len:]\n",
    "        generated_text = tokenizer.decode(last_tokens)\n",
    "\n",
    "    return generated_text.split(\"\\n\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers.set_seed(5)\n",
    "prompt = current_dataset.generate_prompt(sample_q_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "566\n",
      "536\n",
      "566\n",
      "    return float(cars_per_level_more)\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "generated_tokens = model.generate(\n",
    "    tokens.long().cuda(),\n",
    "    use_cache=True,\n",
    "    do_sample=False,\n",
    "    top_k=gen_args.top_k,\n",
    "    temperature=gen_args.temperature,\n",
    "    top_p=gen_args.top_p,\n",
    "    min_length=len(tokens[0]) + gen_args.min_length,\n",
    "    max_length=len(tokens[0]) + gen_args.max_length_after_input,\n",
    "    num_return_sequences=gen_args.num_return_sequences,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    ")\n",
    "\n",
    "list_outputs = preproc_gen_toks(\n",
    "    generated_tokens, len(tokens[0]), tokenizer\n",
    ")\n",
    "print(len(tokens[0]))\n",
    "print(len(tokens[0]) + gen_args.max_length_after_input)\n",
    "print(list_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def exercise1():\n",
      "    \"\"\"\n",
      "    To run his grocery store, Mr. Haj needs $4000 a day. This money is used to pay for orders done, delivery costs and employees' salaries. If he spends 2/5 of the total operation costs on employees' salary and 1/4 of the remaining amount on delivery costs, how much money he pays for the orders done?\n",
      "    \"\"\"\n",
      "    cost_per_day = 4000\n",
      "    employees_cost = cost_per_day * 2 / 5\n",
      "    delivery_costs = (cost_per_day - employees_cost) * 1 / 4\n",
      "    orders_costs = cost_per_day - delivery_costs - employees_cost\n",
      "    return float(orders_costs)\n",
      "\n",
      "\n",
      "def exercise2():\n",
      "    \"\"\"\n",
      "    Sue works in a factory and every 30 minutes, a machine she oversees produces 30 cans of soda. How many cans of soda can one machine produce in 8 hours?\n",
      "    \"\"\"\n",
      "    cans_per_30_minutes = 30\n",
      "    cans_per_minute = cans_per_30_minutes / 30\n",
      "    cans_per_hour = cans_per_minute * 60\n",
      "    cans_per_8_hours = cans_per_hour * 8\n",
      "    return float(cans_per_8_hours)\n",
      "\n",
      "\n",
      "def exercise3():\n",
      "    \"\"\"\n",
      "    Mr. Rainwater has some goats, 9 cows and some chickens. He has 4 times as many goats as cows and 2 times as many goats as chickens. How many chickens does he have?\n",
      "    \"\"\"\n",
      "    goats_cows_ratio = 4 / 1\n",
      "    goats_chickens_ratio = 2 / 1\n",
      "    nr_cows = 9\n",
      "    nr_goats = 9 * goats_cows_ratio\n",
      "    nr_chickens = nr_goats / goats_chickens_ratio\n",
      "    return float(nr_chickens)\n",
      "\n",
      "\n",
      "def exercise4():\n",
      "    \"\"\"\n",
      "    In a town, there is a multi-story parking lot, which has room for 425 cars. The parking lot has 5 levels, each of the same size. How many more cars can one level fit if there are already 23 parked cars on that level?\n",
      "    \"\"\"\n",
      "    cars_per_level = 425\n",
      "    cars_per_level_23 = 23\n",
      "    cars_per_level_more = cars_per_level - cars_per_level_23\n"
     ]
    }
   ],
   "source": [
    "prompt += \"\\n\" + list_outputs\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c59954e50921301bece1313ab371cee7cd99362dbd740142445e95aebb494b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('CodeGen_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
