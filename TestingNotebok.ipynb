{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import os\n",
    "from xml.etree import ElementTree\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import GPTNeoForCausalLM\n",
    "\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "cur_dir = os.getcwd()\n",
    "os.chdir(os.path.join(cur_dir, 'data'))\n",
    "!git clone https://gitlab.cs.washington.edu/ALGES/TACL2015.git\n",
    "!git clone https://github.com/chaochun/nlu-asdiv-dataset.git\n",
    "!git clone https://github.com/openai/grade-school-math.git\n",
    "os.chdir(cur_dir)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: destination path 'TACL2015' already exists and is not an empty directory.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: destination path 'nlu-asdiv-dataset' already exists and is not an empty directory.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "fatal: destination path 'grade-school-math' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def read_string_from_file(path):\n",
    "    with open(path, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "def sample_asdiv(dataset_path):\n",
    "    dom = ElementTree.parse(dataset_path)\n",
    "\n",
    "    #XML parsing\n",
    "    body_list = dom.findall('ProblemSet/Problem/Body')\n",
    "    answer_list = dom.findall('ProblemSet/Problem/Answer')\n",
    "    question_list = dom.findall('ProblemSet/Problem/Question')\n",
    "    formula_list = dom.findall('ProblemSet/Problem/Formula')\n",
    "    stype_list = dom.findall('ProblemSet/Problem/Solution-Type')\n",
    "\n",
    "    #Randomly choose a problem\n",
    "    rand_index = np.random.randint(0, len(body_list))\n",
    "\n",
    "    return f\"{body_list[rand_index].text} {question_list[rand_index].text}\", formula_list[rand_index].text\n",
    "\n",
    "def sample_gsm8k(dataset_path):\n",
    "    with open(dataset_path) as fh:\n",
    "        data = [json.loads(line) for line in fh.readlines() if line]\n",
    "\n",
    "    # Randomly choose a problem\n",
    "    rand_index = np.random.randint(0, len(data))\n",
    "    problem = data[rand_index]\n",
    "    return problem['question'], re.findall(r\"#### \\w+\", problem[\"answer\"])[0][5:]\n",
    "\n",
    "def sample_singleEq(dataset_path):\n",
    "    with open(dataset_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Randomly choose a problem\n",
    "    rand_index = np.random.randint(0, len(data))\n",
    "    problem = data[rand_index]\n",
    "    return problem['sQuestion'], problem['lSolutions']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#genji_model = \"\"\n",
    "gptj_model = \"EleutherAI/gpt-j-6B\"\n",
    "codeparrot_model = \"lvwerra/codeparrot\"\n",
    "\n",
    "asdiv_path = \"data/nlu-asdiv-dataset/dataset/ASDiv.xml\"\n",
    "gsm8k_path = \"data/grade-school-math/grade_school_math/data/train.jsonl\"\n",
    "singleEq_path = \"data/TACL2015/questions.json\" "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "\"\"\"Choose the dataset you want to test\"\"\"\n",
    "#dataset_path = gsm8k_path\n",
    "#dataset_path = singleEq_path\n",
    "dataset_path = asdiv_path\n",
    "\n",
    "\"\"\"Load the priming text to add to the prompt and sample a question\"\"\"\n",
    "#priming_text = read_string_from_file(\"data/priming_texts/gsm8k.txt\")\n",
    "#priming_text = read_string_from_file(\"data/priming_texts/singleEq.txt\")\n",
    "priming_text = read_string_from_file(\"data/priming_texts/asdiv.txt\")\n",
    "\n",
    "#sample_q, sample_a = sample_gsm8k(dataset_path)\n",
    "#sample_q, sample_a = sample_singleEq(dataset_path)\n",
    "sample_q, sample_a = sample_asdiv(dataset_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "prompt = f\"{priming_text}\\n\\n#{sample_q}\"\n",
    "print(prompt)\n",
    "print(\"\\n\" + \"-\"*100 + \"\\n\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "#Sandra took six cups of coffee and Marcie took two cups of coffee. print the number of cups of coffee did Sandra and Marcie take in total?\n",
      "cups_sandra = 6\n",
      "cups_marcie = 2\n",
      "total_cups = cups_sandra + cups_marcie\n",
      "print(total_cups)\n",
      "\n",
      "#Mrs. Franklin had 58 Valentines. Mrs. Franklin gave some to her students. Now she has 16. Write a program that prints how many Valentines did Mrs. Franklin give to her students?\n",
      "valentines_franklin = 58\n",
      "valentines_students = 16\n",
      "total_valentines = valentines_franklin - valentines_students\n",
      "print(total_valentines)\n",
      "\n",
      "#Susie's father repaired the bookshelves in the reading room. If he has 210 books to be distributed equally on the 10 shelves he repaired, write a program that prints how many books will each shelf contain?\n",
      "books_susie = 210\n",
      "shelves_susie = 10\n",
      "books_per_shelf = books_susie / shelves_susie\n",
      "print(books_per_shelf)\n",
      "\n",
      "#Michelle likes to save money every now and then so that she has money to buy the things that she wants. One day, she decided to count her savings. She opened her piggy bank and sorted out the different coins and dollar bills. If she counted a total of 20 nickels (a nickel is equivalent to 5 cents), write a program that prints what is the total value of money does she have in nickels?\n",
      "nickels = 20\n",
      "nickel_value = 5\n",
      "total_nickels = nickels * nickel_value\n",
      "print(total_nickels)\n",
      "\n",
      "#Pete, Bryan and Philip are cousins. Pete's age is one-third of Bryan and Philip is five years elder than Bryan. If the sum of the age of the cousins is 40, find the ages of each.\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\"\"\"GPT-J and codeparrot models run in HFTest venv\"\"\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(gptj_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(gptj_model).eval().cuda()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "\"\"\"Genji model run in HFTest_genji venv\"\"\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\"NovelAI/genji-python-6B\").eval().cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-2.7B\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Downloading: 100%|██████████| 1.43k/1.43k [00:00<00:00, 1.18MB/s]\n",
      "Downloading: 100%|██████████| 12.6G/12.6G [21:51<00:00, 9.59MB/s]\n",
      "Downloading: 100%|██████████| 1.46k/1.46k [00:00<00:00, 1.32MB/s]\n",
      "Downloading: 100%|██████████| 798k/798k [00:00<00:00, 1.92MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 831kB/s] \n",
      "Downloading: 100%|██████████| 90.0/90.0 [00:00<00:00, 83.2kB/s]\n",
      "Downloading: 100%|██████████| 200/200 [00:00<00:00, 178kB/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "tokens = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "generated_tokens = model.generate(tokens.long().cuda(), \n",
    "                                  use_cache=True, \n",
    "                                  do_sample=True, \n",
    "                                  top_k=50, \n",
    "                                  temperature=0.4, \n",
    "                                  top_p=0.9, \n",
    "                                  repetition_penalty=1.125, \n",
    "                                  min_length=1, \n",
    "                                  max_length=len(tokens[0]) + 100, \n",
    "                                  pad_token_id=tokenizer.eos_token_id)\n",
    "\n",
    "last_tokens = generated_tokens[0][len(tokens[0]):]\n",
    "generated_text = tokenizer.decode(last_tokens)\n",
    "print(\"Generation:\\n\" + generated_text)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Generation:\n",
      "\n",
      "age_peter = 30\n",
      "age_bryan = 25\n",
      "age_philip = 35\n",
      "sum_of_ages = peter + bryan + philip\n",
      "print(sum_of_ages)\n",
      "\n",
      "#A man bought three pairs of shoes at $10 each. He paid for them with a credit card. The price of the credit card was $20. What was the cost of the shoes?\n",
      "cost_shoes = 10\n",
      "credit_card_price\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('HFtests': venv)"
  },
  "interpreter": {
   "hash": "5ea8e8bf8ca3b9f65e7cf95ea2223aa98d68a16922d567d33b86408fe49c3092"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}