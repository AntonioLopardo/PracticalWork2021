{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/CodeGen_env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "import dataset_handler as dh\n",
    "import testing_utils as tu\n",
    "from termcolor import colored\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "priming_text_path = \"data/priming_texts/gsm8k/codegen/func_eq_short.txt\"\n",
    "gsm8k_path = \"data/grade-school-math/grade_school_math/data/train.jsonl\"\n",
    "\n",
    "current_dataset = dh.init_dataset_from_name(\n",
    "        \"gsm8k\", primingtext_path=priming_text_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4547 1364 2033 2409 2181 5082 2184 6995 5480 3775 2096 5997 5205 4924\n",
      " 4211  458 4763  620 4365 6025 1085 6287 5469 3426 3602  270 7270 4445\n",
      " 6584  777 4659 7108 5045 3893 5959 2875 6314 4506 6466 1894 3081 1765\n",
      " 3453 2542 7249 3947 3855 1500 4443  491  575  598 7199 3092 2733 2581\n",
      " 6856 7132 2076  735 2607 1418 2989 5122 4518 4295 6111 3195 1400 1241\n",
      " 5060 3365 5483 4546 1574 5430 4054 4519 6778 5166 3718 2399 3232 4937\n",
      " 7138 2055 5502 1417 2018 4838 6570 6163 4923 4400 1929 6672 6256  206\n",
      "  118 4857]\n"
     ]
    }
   ],
   "source": [
    "tu.set_all_seeds()\n",
    "\n",
    "rand_indexes = np.random.randint(0, len(current_dataset.data), 100)\n",
    "print(rand_indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [current_dataset.data[i] for i in rand_indexes]\n",
    "test_data = [elem[\"question\"] for elem in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Carol sells tickets for an exhibition. During three days she sold tickets worth $960. One ticket costs $4. How many tickets on average did she sell during one of these three days?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "#pickle loads the model\n",
    "clustering_model = pickle.load(open(\"clustering_model_3.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = test_data\n",
    "corpus_embeddings = embedder.encode(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "labels = list(clustering_model.predict(corpus_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(f\"{pkl_dir}cluster_3_pass_at_k.pkl\", \"rb\") as f:\\n    cluster_3_pass_at_k = pickle.load(f)'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkl_dir = \"clustering_exp/3_cluster/\"\n",
    "\n",
    "with open(f\"{pkl_dir}cluster_0_pass_at_k.pkl\", \"rb\") as f:\n",
    "    cluster_0_pass_at_k = pickle.load(f)\n",
    "with open(f\"{pkl_dir}cluster_1_pass_at_k.pkl\", \"rb\") as f:\n",
    "    cluster_1_pass_at_k = pickle.load(f)\n",
    "with open(f\"{pkl_dir}cluster_2_pass_at_k.pkl\", \"rb\") as f:\n",
    "    cluster_2_pass_at_k = pickle.load(f)\n",
    "'''\n",
    "with open(f\"{pkl_dir}cluster_3_pass_at_k.pkl\", \"rb\") as f:\n",
    "    cluster_3_pass_at_k = pickle.load(f)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_pass_at_k = []\n",
    "max_dict = {}\n",
    "max_dict[0] = []\n",
    "max_dict[1] = []\n",
    "max_dict[2] = []\n",
    "#max_dict[3] = []\n",
    "\n",
    "\n",
    "for i, label in enumerate(labels):\n",
    "    cand_list = [\n",
    "        cluster_0_pass_at_k[i],\n",
    "        cluster_1_pass_at_k[i],\n",
    "        cluster_2_pass_at_k[i],\n",
    "        #cluster_3_pass_at_k[i],\n",
    "    ]\n",
    "    max_cand = cand_list[label]\n",
    "    max_dict[cand_list.index(max_cand)].append(i)\n",
    "    agg_pass_at_k.append(max_cand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregate prompts - Pass@3 = 0.38300000000000006\n",
      "\n",
      "cluster_0: 75\n",
      "cluster_1: 20\n",
      "cluster_2: 5\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nAggregate prompts - Pass@{3} = {np.mean(np.array(agg_pass_at_k))}\\n\")\n",
    "print(f\"cluster_0: {len(max_dict[0])}\")\n",
    "print(f\"cluster_1: {len(max_dict[1])}\")\n",
    "print(f\"cluster_2: {len(max_dict[2])}\")\n",
    "#print(f\"cluster_3: {len(max_dict[3])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "General prompts - Pass@3 = 0.355\n"
     ]
    }
   ],
   "source": [
    "with open(f\"{pkl_dir}general_pass_at_k.pkl\", \"rb\") as f:\n",
    "    general_pass_at_k = pickle.load(f)\n",
    "\n",
    "print(f\"General prompts - Pass@{3} = {np.mean(np.array(general_pass_at_k))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(np.nonzero(np.array(agg_pass_at_k)))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c59954e50921301bece1313ab371cee7cd99362dbd740142445e95aebb494b1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('CodeGen_env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
